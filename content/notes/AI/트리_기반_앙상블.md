---
title: 트리 기반 앙상블
category:
  - AI
---

`Tree-based Ensemble`

## 1. 결정 트리 (Decision Tree)

- 입력 변수(피처)를 기준으로 **if–else 규칙**을 반복해 나누고, 잎 노드에서 예측값(평균 등)을 냄
- 예: "어떤 값 > 300이면 왼쪽, 아니면 오른쪽"처럼 구간을 나누어 조합

## 2. 앙상블 (Ensemble)

- **여러 개의 모델**을 만들고, 그 예측을 합쳐서(평균, 투표 등) 최종 예측을 내는 방식
- 한 가지 모델만 쓰는 것보다 **분산 감소·과적합 완화** 효과

## 3. 트리 기반 앙상블

- **기본 구성요소가 모두 결정 트리**인 앙상블
- 트리를 여러 개 쌓거나 조합하는 방식만 다름

| 모델 | 아이디어 |
| --- | --- |
| Random Forest | 여러 트리를 **독립적으로** 학습시키고, 각 트리가 다른 데이터·피처 샘플을 보게 해서 예측 평균 |
| ExtraTrees | Random Forest와 비슷하지만, 분할 시점을 **무작위**로 해서 트리 다양성 증가 |
| GBM (Gradient Boosting) | 트리를 **순차적으로** 추가. 새 트리는 이전 트리들의 **잔차(오차)**를 줄이는 방향으로 학습 |
| XGBoost, LightGBM, CatBoost | GBM의 변형. 손실 함수·정규화·분할 탐색 방식·범주형 처리 등이 다름 |
| NGBoost | Boosting이지만 예측을 **분포(평균+분산)**로 내는 probabilistic boosting |

공통점: **피처를 구간으로 나누어 비선형·상호작용**을 잘 잡아냄

## 관련 노트

- [Machine Learning](/notes/Machine_Learning/) - 지도학습/비지도학습/강화학습
- [기계학습](/notes/기계학습/) - 기계학습 알고리즘 유형
- [신경망](/notes/신경망/) - 딥러닝 기반 모델과 비교
