---
title: 데이터 중복 제거
---

## 데이터 중복 제거의 개요
### 데이터 중복 제거의 정의
> 데이터 중복 제거란 서로 다른 데이터(파일)들 간에 중복되는 부분을 검출해내고, 중복된 부분을 제거함으로써 스토리지 활용의 효율성을 높이는 활동

### 데이터 중복 제거의 등장 배경
* 용량 대비 스토리지의 가격이 급속히 하락
* 데이터의 크기에 대한 제약은 점점 사라짐
* 다뤄야할 데이터의 양은 점점 더 폭증
* 급증하는 데이터를 백업하기 위해서 방대한 스토리지 및 시스템이 필요
* 최소한의 비용으로 방대한 데이터를 유지 및 관리 필요

## 데이터 중복 제거의 개념 및 이점
### 데이터 중복 제거의 개념도
![](http://cfile1.uf.tistory.com/image/114413134C2DF01008993F)
동일한 매뉴얼 파일 100개를 스토리지에 저장해야 하는 대신 1개 파일 저장과 100개 포인터로 대체

### 데이터 중복 제거의 이점
* 스토리지 비용 절감: 고가의 스토리지 시스템을 확장하는 비용을 절감
* 회선 비용 절감: 네트워크 사용량 감소로 인한 회선 비용 절감 효과
* 백업 효율성 향상: 대부분이 실제로는 중복되는 부분을 많이 포함
* 높은 수준의 [[SLA]] 보장: 백업 수행 주기를 작게 유지
* 가상화 이미지 백업: 서버 가상화 시대 사용가치 증대

## 데이터 중복 제거의 종류
### 중복 제거의 수준에 따른 분류

|분류|설명|문제점|
|---|---|---|
|SIS(Single Instance Storage)|파일 전체가 중복되는 경우에만 중복 제거|효율성 면에서 떨어짐|
|고정 길이 블록 제거|정해진 길이의 블록 포인터로 관리 및 제거||
|가변 길이 블록 제거|가변적인 길이의 블록 포인터로 관리 및 제거||

### 중복 제거가 일어나는 장소에 따른 분류

|분류|설명|문제점|
|---|---|---|
|소스 중복 제거|데이터 소스에서 중복 제거|많은 CPU 작업을 요구하여 오버헤드 발생|
|타깃 중복 제거|소스 디바이스에서 보내진 원본 데이터를 타깃 스토리지 측에서 제거|데이터 크기에 따라 대랑 트래픽 발생, 백업/복구 시간 증대|
|하이브리드 방식 제거|소스와 타깃 사이에 전용 어플리케이션으로 제거|전용 어플라이언스 비용 및 확장성 문제, 병목현상 가능|

### 중복 제거가 일어나는 시점에 따른 분류 

|분류|설명|문제점|
|---|---|---|
|사후 처리 중복 제거|임시 디스크에 저장 후 추후 시점 중복 제거|별도의 스토리지 필요, 임시 데이터 많은 경우 작업 지연|
|인라인 중복 제거|데이터를 수신 받은 후 바로 중복 제거|데이터 송수신 시 오버헤드 발생|

### 중복 제거의 방식에 따른 분류 

|분류|설명|문제점|
|---|---|---|
|해시 함수 사용|특정 파일 블록, 비트 스트림 해시를 비교하여 중복 간주|해시 충돌 가능성|
|델타 기반 중복 제거|기존 복제본 기준 변동된 내용만 기록|디스크 입출력이 많음|

## 데이터 중복 제거의 향후 발전 방향
* 시스템 오버헤드 최소화로 백업을 포함한 2차 스토리지에 국한되지 않고 1차 스토리지 활용
* 표준화 인터페이스를 통해 각종 SW 솔루션의 수정이나 별도의 통합 작업 없이 데이터 중복 제거
